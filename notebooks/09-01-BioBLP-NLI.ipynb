{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioBLP Demo notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to showcase the BioBLP as a Natural Language Interface (NLI) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Super basic UI\n",
    "    - 3 widgets:\n",
    "        - DrugBank ID input (textbox/dropdown?)\n",
    "        - Relation dropdown (Drug-Disease Association)\n",
    "        - Disease description (textbox)\n",
    "        \n",
    "- Load pre-trained BioBLP-D\n",
    "- Post input functionality:\n",
    "    - Setting <subject, relation>\n",
    "    - Tokenization of input text (disease description) :: TextEntityPropertyPreprocessor\n",
    "    - Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE STUFF\n",
    "import os.path as osp\n",
    "import torch\n",
    "\n",
    "from bioblp.loaders.preprocessors import TextEntityPropertyPreprocessor\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERACTIVE UI STUFF\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "layout = widgets.Layout(width='auto', height='40px') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fe44ca3c8a41d584807bf7f50fa38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict potential drugs for the described disease!', layout=Layout(height='40px', width='a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BASIC BUTTON FUNC -> we want a TextArea for disease desc AND a button to get predictions back!\n",
    "btn = widgets.Button(description='Predict potential drugs for the described disease!',\n",
    "                     layout=layout)\n",
    "\n",
    "def btn_eventhandler(obj):\n",
    "    print('Hello from the {} button!'.format(obj.description))\n",
    "    \n",
    "btn.on_click(btn_eventhandler)\n",
    "\n",
    "display(btn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT AREA FOR DESCRIPTIONS\n",
    "txtsl = widgets.Textarea(\n",
    " placeholder='Enter the description of the disease you are interested in...',\n",
    " description='Disease description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe62d6394094e25a87f0939759822b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Predict potential drugs for the described disease!', layout=Layout(height='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PUTTING IT ALL TOGETHER\n",
    "input_widgets = widgets.HBox(\n",
    "[btn])\n",
    "display(input_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DISEASE\n",
    "# D000006\n",
    "test_disease_descr = '''A clinical syndrome with acute abdominal pain that is severe, \n",
    "localized, and rapid in onset. Acute abdomen may be caused by a variety of disorders, injuries, or diseases.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRETRAINED MODEL\n",
    "base_path = osp.join('..', 'models', 'bioblpd-38uz9fjs')\n",
    "model_path = osp.join(base_path, 'trained_model.pkl')\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD BIOBERT STUFF + TEXT PREPROCESS + TOKENIZER\n",
    "BASE_MODEL = 'dmis-lab/biobert-base-cased-v1.2'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "preprocessor = TextEntityPropertyPreprocessor(tokenizer, max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   170,  7300,  9318,  1114, 12104, 24716,  2489,  1115,  1110,\n",
       "          5199,   117, 25813,   117,  1105,  6099,  1107, 15415,   119, 12104,\n",
       "         14701,  1336,  1129,  2416,  1118,   170,  2783,  1104, 11759,   117,\n",
       "          5917,   117,  1137,  8131,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOKENIZE THE INPUT DESCRIPTION TO PASS AS MODEL INPUT\n",
    "tokens = tokenizer(test_disease_descr, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.property_encoder.type_id_to_encoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'BatchEncoding' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/BioBLP/bioblp/models/encoders.py:165\u001b[0m, in \u001b[0;36mTransformerTextEncoder.forward\u001b[0;34m(self, tokens, device)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: Tensor, device: torch\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Clip to maximum length in batch and move to device\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (\u001b[43mtokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    166\u001b[0m     max_length \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    167\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, :max_length]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'BatchEncoding' and 'int'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder.forward(tokens, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaBioBLP39",
   "language": "python",
   "name": "condabioblp39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
