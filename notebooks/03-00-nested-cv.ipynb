{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8467842-5b37-4dc9-83f0-a684ed4a5fdd",
   "metadata": {},
   "source": [
    "# Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "259edda9-e110-4e05-b1de-2965c45ef58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from bioblp.data import COL_EDGE, COL_SOURCE, COL_TARGET\n",
    "from bioblp.logging import get_logger\n",
    "\n",
    "\n",
    "logger = get_logger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134fd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data/\")\n",
    "DATA_SHARED = Path(\"/home/jovyan/workbench-shared-folder/bioblp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d5ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi_benchmark_path = DATA_SHARED.joinpath('data/benchmarks/benchmarks/dpi_fda.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099a1504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>edg</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB01079</td>\n",
       "      <td>DPI</td>\n",
       "      <td>Q13639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB00114</td>\n",
       "      <td>DPI</td>\n",
       "      <td>P20711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB01158</td>\n",
       "      <td>DPI</td>\n",
       "      <td>P13637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       src  edg     tgt\n",
       "0  DB01079  DPI  Q13639\n",
       "1  DB00114  DPI  P20711\n",
       "2  DB01158  DPI  P13637"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpi_bm = pd.read_csv(dpi_benchmark_path, sep='\\t', names=[COL_SOURCE, COL_EDGE, COL_TARGET])\n",
    "dpi_bm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f9f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b220f7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19161"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dpi_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6943fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "ent2id_map = pd.read_csv(DATA_SHARED.joinpath(\"models/1baon0eg/training_triples/entity_to_id.tsv.gz\"), sep=\"\\t\", compression=\"gzip\")\n",
    "ent2id_map = {v[1]: v[0] for v in ent2id_map.values}\n",
    "\n",
    "def get_ent_ids_for_entity_list(entity_list: List[str], ent2id_map):\n",
    "    ids = [ent2id_map.get(ent) for ent in entity_list]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c42a0412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model from /home/jovyan/workbench-shared-folder/bioblp/models/1baon0eg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_dir = DATA_SHARED.joinpath('models/1baon0eg')\n",
    "print(f'Loading trained model from {model_dir}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load(model_dir.joinpath(f\"trained_model.pkl\"), map_location=device)\n",
    "#if not torch.cuda.is_available():\n",
    "#    model.device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba5e7770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(106339, 512)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_representation = model.entity_representations[0]._embeddings\n",
    "relation_representation = model.relation_representations[0]._embeddings\n",
    "entity_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d19ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi_bm_drugs = list(dpi_bm.src.values)\n",
    "print(ent2id_map)\n",
    "drug_ids = get_ent_ids_for_entity_list(dpi_bm_drugs, ent2id_map)\n",
    "print(drug_ids)\n",
    "drug_ids = torch.LongTensor(drug_ids)\n",
    "#drug_embs = model.entity_representations[0](drug_ids)\n",
    "drug_embs = model.entity_representations[0]._embeddings(drug_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi_bm_prots = list(dpi_bm.tgt.values)\n",
    "prot_ids = get_ent_ids_for_entity_list(dpi_bm_prots, ent2id_map)   \n",
    "prot_ids = torch.LongTensor(prot_ids)\n",
    "prot_embs = model.entity_representations[0]._embeddings(prot_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_embs.shape, prot_embs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f016b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "def concatenate(emb1, emb2):\n",
    "    out = torch.cat((emb1, emb2), dim=0).view(1, -1)\n",
    "    return out\n",
    "\n",
    "def average(emb1, emb2):\n",
    "    concat = torch.cat((emb1, emb2), dim=0).view(2, -1)\n",
    "    out = torch.stack((emb1, emb2)).mean(dim=0).view(1,-1)\n",
    "    return out\n",
    "\n",
    "def encode_entity_pair(emb1, emb2, transform:Callable):\n",
    "    return transform(emb1, emb2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = encode_entity_pair(emb1=drug_embs[0, :], emb2=prot_embs[0, :], transform=average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee761be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random as rn\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326edf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2022\n",
    "\n",
    "#\n",
    "# DEFAULT PARAMETERS FOR RR\n",
    "#\n",
    "rf_default_params = {\n",
    "    'n_estimators': 300,\n",
    "    'criterion': 'gini',\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'auto',\n",
    "    'random_state': SEED,\n",
    "    'n_jobs': -1,\n",
    "\n",
    "}\n",
    "\n",
    "lr_default_params = {\n",
    "    'C': 1.0,\n",
    "    'random_state': SEED,\n",
    "    'max_iter': 1000,\n",
    "    'solver': 'lbfgs',\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "\n",
    "\n",
    "#\n",
    "# OPT SPACES FOR RR\n",
    "#\n",
    "\n",
    "rf_search_space = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'n_estimators': np.arange(100, 1201, 200, dtype=int),\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10, 15, 100],\n",
    "    'max_depth': [5, 8, 15, 25, 30, None],\n",
    "    'random_state': [SEED]\n",
    "}\n",
    "\n",
    "lr_search_space = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': np.logspace(-4, 3, 8),\n",
    "    'random_state': [SEED],\n",
    "    'max_iter': [1000],\n",
    "    'solver': ['lbfgs'],\n",
    "    'n_jobs': [-1],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_nested_cv(candidates: list, X, y, scoring: dict,\n",
    "                  outer_n_folds: int = 5, inner_n_folds: int = 2, inner_n_iter: int = 10, shuffle: bool = False,\n",
    "                  random_state: int = SEED, n_jobs: int = 12, refit_param: str = 'fbeta', verbose: int = 0) -> dict:\n",
    "    \"\"\"Nested cross validation routine.\n",
    "    Inner cv loop performs hp optimization on all folds and surfaces\n",
    "    Parameters\n",
    "    ----------\n",
    "    candidates : list\n",
    "        list of (label, estimator, param_dist)\n",
    "    X : np.array\n",
    "        predictor\n",
    "    y : np.ndarray\n",
    "        labels\n",
    "    scoring : dict\n",
    "        dict containing sklearn scorers\n",
    "    outer_n_folds : int, optional\n",
    "        splits for outer cv, by default 5\n",
    "    inner_n_folds : int, optional\n",
    "        splits for inner cv, by default 2\n",
    "    inner_n_iter : int, optional\n",
    "        number of trials within inner fold, by default 10\n",
    "    shuffle : bool, optional\n",
    "        shuffles data before cv, by default True\n",
    "    random_state : int, optional\n",
    "        seed for rng, by default SEED\n",
    "    n_jobs : int, optional\n",
    "        multiprocessing, by default 10\n",
    "    refit_param : str, optional\n",
    "        which metric to optimize for and return refit model, by default 'fbeta'\n",
    "    verbose : int, optional\n",
    "        level of console feedback, by default 0\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        outer cv scores e.g. {name: scores}\n",
    "    \"\"\"\n",
    "    gridcvs = {}\n",
    "\n",
    "    inner_cv = StratifiedKFold(n_splits=inner_n_folds, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    for name, estimator, param_grid in candidates:\n",
    "        gcv = RandomizedSearchCV(\n",
    "                estimator=estimator,\n",
    "                param_distributions=param_grid,\n",
    "                n_iter=inner_n_iter,\n",
    "                scoring=scoring,\n",
    "                n_jobs=1,\n",
    "                cv=inner_cv,\n",
    "                verbose=1,\n",
    "                refit=refit_param,\n",
    "                random_state=random_state)\n",
    "        gridcvs[name] = gcv\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=outer_n_folds, shuffle=shuffle, random_state=random_state)\n",
    "    outer_scores = {}\n",
    "\n",
    "    for name, gs_est in sorted(gridcvs.items()):\n",
    "        nested_score = cross_validate(gs_est,\n",
    "                                      X=X,\n",
    "                                      y=y,\n",
    "                                      scoring=scoring,\n",
    "                                      cv=outer_cv,\n",
    "                                      n_jobs=n_jobs,\n",
    "                                      return_estimator=False,\n",
    "                                      return_train_score=True)\n",
    "\n",
    "        score_to_optimize = nested_score.get('test_{}'.format(refit_param))\n",
    "        logger.info(\n",
    "            f'{name}: outer {refit_param} {100*score_to_optimize.mean():.2f} +/- {100*score_to_optimize.std():.2f}')\n",
    "        outer_scores[name] = nested_score\n",
    "    return outer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1de112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# reproducibility\n",
    "SEED = 2022\n",
    "\n",
    "\n",
    "# def set_seeds(seed: int = SEED):\n",
    "#     os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "#     np.random.seed(SEED)\n",
    "#     tf.random.set_seed(SEED)\n",
    "#     rn.seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "experiment_config = {\n",
    "    \"n_proc\": 1,\n",
    "    \"n_iter\": 3,\n",
    "    \"inner_n_folds\": 3,\n",
    "    \"outer_n_folds\": 5,\n",
    "    \"param\": \"fbeta\"\n",
    "}\n",
    "\n",
    "# data_dir = experiment_base_path.joinpath(experiment_config[\"data_dir\"])\n",
    "# out_dir = experiment_base_path.joinpath(experiment_config[\"out_dir\"])\n",
    "\n",
    "# mkdir(out_dir)\n",
    "\n",
    "n_proc = config[\"n_proc\"]\n",
    "n_iter = experiment_config[\"n_iter\"]\n",
    "inner_n_folds = experiment_config[\"inner_n_folds\"]\n",
    "outer_n_folds = experiment_config[\"outer_n_folds\"]\n",
    "optimize_param = experiment_config[\"param\"]\n",
    "\n",
    "# set_seeds(seed=SEED)\n",
    "\n",
    "shuffle = False\n",
    "\n",
    "exp_output = defaultdict(dict)\n",
    "exp_output['settings'] = {\n",
    "    'data_dir': data_dir,\n",
    "    'n_iter': n_iter,\n",
    "    'inner_n_folds': inner_n_folds,\n",
    "    'outer_n_folds': outer_n_folds,\n",
    "    'optimize_param': optimize_param,\n",
    "    'shuffle': shuffle,\n",
    "    'seed': SEED\n",
    "}\n",
    "\n",
    "start = time()\n",
    "\n",
    "logger.info(\"Starting model building script at {}.\".format(start))\n",
    "\n",
    "############\n",
    "# Load data\n",
    "############\n",
    "logger.info(\"Loading training data...\")\n",
    "\n",
    "X_train = np.load(data_dir.joinpath('X_train.npy'))\n",
    "y_train = np.load(data_dir.joinpath('y_train.npy'))\n",
    "\n",
    "logger.info(\"Resulting shapes X_train: {}, y_train: {}\".format(X_train.shape, y_train.shape))\n",
    "logger.info(\"Counts in y_train: {}\".format(np.unique(y_train, return_counts=True)))\n",
    "############\n",
    "# Setup classifiers & pipelines\n",
    "############\n",
    "\n",
    "lr_label = 'LR'\n",
    "clf_lr = LogisticRegression(**lr_default_params)\n",
    "\n",
    "rf_label = 'RF'\n",
    "clf_rf = RandomForestClassifier(**rf_default_params)\n",
    "\n",
    "\n",
    "# record default params\n",
    "exp_output['default_params']: {\n",
    "    lr_label: lr_default_params,\n",
    "    rf_label: rf_default_params\n",
    "}\n",
    "\n",
    "############\n",
    "# Setup grids\n",
    "############\n",
    "exp_output['grids']: {\n",
    "    lr_label: lr_search_space,\n",
    "    rf_label: rf_search_space\n",
    "}\n",
    "\n",
    "############\n",
    "# Compare models\n",
    "############\n",
    "candidates = [\n",
    "    (lr_label, clf_lr, lr_search_space),\n",
    "    (rf_label, clf_rf, rf_search_space)\n",
    "]\n",
    "\n",
    "scorer = {\n",
    "    'AUC': make_scorer(roc_auc_score),\n",
    "    'fbeta': make_scorer(fbeta_score, beta=1, average='micro'),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "nested_cv_scores = run_nested_cv(\n",
    "    candidates=candidates,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    scoring=scorer,\n",
    "    inner_n_folds=inner_n_folds,\n",
    "    inner_n_iter=n_iter,\n",
    "    outer_n_folds=outer_n_folds,\n",
    "    shuffle=shuffle,\n",
    "    n_jobs=n_proc,\n",
    "    refit_param=optimize_param,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "for algo, scores in nested_cv_scores.items():\n",
    "    logger.info(\"Scores {}: {}\".format(algo, scores))\n",
    "\n",
    "exp_output['results'] = nested_cv_scores\n",
    "\n",
    "logger.info(exp_output)\n",
    "\n",
    "run_timestamp = int(time())\n",
    "# file_out = out_dir.joinpath('nested_cv_scores_{}.npy'.format(run_timestamp))\n",
    "# logger.info(\"Saving to {}\".format(file_out))\n",
    "# np.save(file_out, exp_output)\n",
    "\n",
    "end = time()\n",
    "\n",
    "logger.info(\"Ran script in {} seconds\".format(str(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ccdb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('bioblp-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c313b0b0929f94c03130caa81adcdac46c3c408d7f1caca6c1104b192c16f937"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
